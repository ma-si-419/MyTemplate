今後3Dのシェーダを取り扱っていきますが、
かなり難易度が高いです。
2Dのシェーダと比べるとはるかに高いです。
もし、「わからん」となったら、あまり無理しなくていいです
そのために、先に2Dのポストエフェクトにシェーダを使用する
お話をしていました。

なので、最悪でも
2Dゲームにシェーダでエフェクトをかける
3Dゲームをいったん作っておいて、あとからそのレンダーターゲットに
ポストエフェクトを2Dとして翔

これであれば「シェーダわかってますよ」というのをアピールできる。
某社みたいに「3Dじゃないと受付ませーん！」という会社の場合でも

まずはLoadModel+DrawModelでゲーム作っておいて、RTだけあとから
ポストエフェクトをかける…だけでも、たぶんかなり強いと思います。

シェーダはたぶん、皆さんが思ってるよりもかける人がはるかに少ない。
→シェーダが書けるだけでも、かなりアドバンテージになります。

シェーダが書ける→応用範囲が実は広い
	レンダリング以外にも用途がある。
	ComputeShader(AI,衝突判定,最適化,計算,音楽)

スキニングとは…スキンドメッシュともいう

Bone:骨
Skin:皮

バーチャ2くらいだと、各関節が完全に分離してました。
継ぎ目が見えてました。(段ボールガンダムみたいな感じです)

バーチャ3くらいから、「スキンメッシュ(SkinnedMesh)」という技法が
使用されて、関節の継ぎ目が見えなくなりました。

どうやってるのかというと、
昔：前腕オブジェクトを回転、上腕オブジェクトを回転→継ぎ目が出る
	オブジェクトに属する頂点すべてを回転
現代：前腕ボーンを回転、上腕ボーンを回転
	ボーンの影響範囲にある頂点を回転させる
	ただし、前腕と上腕の中間にあるものは
	頂点ごとに「影響率」パラメータがあり、どちらにより
	影響を受けるのかというのが設定されている。
	
このことをスキニング(スキンドメッシュ)といいます。
これで滑らかにアニメーションすることをスキンメッシュアニメーション
といいます。

ところがこれ、めちゃくちゃ難しいので、今はこれを考えずに
3D表示の事だけ考えます。

法線マッピングはご存じだと思います。
これを3Dでやろうとすると結構ややこしいです。何故かというと
法線マップは元の法線を上下左右にずらすことで、表面の凸凹を表現
していました。

なんだけど、この上下左右ttえどのベクトル？
で、この上下左右のベクトルに当たるのがTangent(接線ベクトル)と
Binormal(従法線ベクトル)です。

接線が決まってる。あとは、接線方向を決めれば従法線は勝手に決まります。
ちなみに接線ベクトルはどうやって決めているのか…なんですが、
MV1が出力されるときに、インデックス情報から三角性を構築しますが。

接線ベクトルはその三角形の辺のベクトルから算出しています。
従法線の方は、法線ベクトルと、接線ベクトルの外積から求めます。

という感じで、実は法線マップ(バンプマップ)も意外とややこしい

なので、今回はシンプルに、法線マップなし、スキニングなしのモデルとして
プログラムを書いていきます。

今回は、シンプルシェーダを使いますので、頂点情報は比較的少ないですが
定数バッファが結構たくさんあります。

DX_D3D11_VS_CONST_BUFFER_COMMONこれが
レジスタ0番に当たります。

//これがレジスタ0番
struct DX_D3D11_CONST_BUFFER_COMMON
{
	DX_D3D11_CONST_LIGHT		Light[ DX_D3D11_COMMON_CONST_LIGHT_NUM ] ;			// ライトパラメータ
	DX_D3D11_CONST_MATERIAL		Material ;											// マテリアルパラメータ
	DX_D3D11_VS_CONST_FOG		Fog ;												// フォグパラメータ
} ;

// ライトパラメータ
struct DX_D3D11_CONST_LIGHT
{
	DX_D3D11_SHADER_INT			Type ;					// ライトタイプ( DX_LIGHTTYPE_POINT など )
	DX_D3D11_SHADER_INT3		Padding1 ;				// パディング１

	DX_D3D11_SHADER_FLOAT3		Position ;				// 座標( ビュー空間 )
	DX_D3D11_SHADER_FLOAT		RangePow2 ;				// 有効距離の２乗

	DX_D3D11_SHADER_FLOAT3		Direction ;				// 方向( ビュー空間 )
	DX_D3D11_SHADER_FLOAT		FallOff ;				// スポットライト用FallOff

	DX_D3D11_SHADER_FLOAT3		Diffuse ;				// ディフューズカラー
	DX_D3D11_SHADER_FLOAT		SpotParam0 ;			// スポットライト用パラメータ０( cos( Phi / 2.0f ) )

	DX_D3D11_SHADER_FLOAT3		Specular ;				// スペキュラカラー
	DX_D3D11_SHADER_FLOAT		SpotParam1 ;			// スポットライト用パラメータ１( 1.0f / ( cos( Theta / 2.0f ) - cos( Phi / 2.0f ) ) )

	DX_D3D11_SHADER_FLOAT4		Ambient ;				// アンビエントカラーとマテリアルのアンビエントカラーを乗算したもの

	DX_D3D11_SHADER_FLOAT		Attenuation0 ;			// 距離による減衰処理用パラメータ０
	DX_D3D11_SHADER_FLOAT		Attenuation1 ;			// 距離による減衰処理用パラメータ１
	DX_D3D11_SHADER_FLOAT		Attenuation2 ;			// 距離による減衰処理用パラメータ２
	DX_D3D11_SHADER_FLOAT		Padding2 ;				// パディング２
} ;

ディフューズ・スペキュラー・アンビエント
ディフューズ計算
diffuse = dcol * saturete(dot(L,N));

|cos -sin 0||x| = xcos - ysin + a
|sin  cos 0||y|   xsin + ycos + b
| a    b  1||1|           1


R R R Tx |x| = Rx+Ry+Rz + Tx
R R R Ty |y|   Rx+Ry+Rz + Ty
R R R Tz |z|   Rx+Ry+Rz + Tz
0 0 0 1  |1|         1

//DxLibの場合
R R R Tx |x| = Rx+Ry+Rz + Tx
R R R Ty |y|   Rx+Ry+Rz + Ty
R R R Tz |z|   Rx+Ry+Rz + Tz


//平行移動させたくない場合wに0を入れる
R R R Tx |x| = Rx+Ry+Rz + Tx
R R R Ty |y|   Rx+Ry+Rz + Ty
R R R Tz |z|   Rx+Ry+Rz + Tz
0 0 0 1  |0|         0


SV_POSITIONとPOSITIONの違い

SV_のSVはSystemValueの略です
つまり、ラスタライザに食わせる値(保管されない…僕らの思ってるような補間になってない)

SV_POSITIOnはラスタライザが使う値なので、ピクセルシェーダで
使わないほうがいい
なので、空間的な3D座標をピクセルシェーダで知りたければ、別枠で
POSITION[n]として、定義して、それを送るべき
DxLibの場合
PとPositionがある
Pはプロジェクション変換までされて、そのうえでの保管される座標値
Positionは、ワールド変換(回転、平行移動)だけが行われているため
元の3D座標を示しています。

スペキュラ(ハイライト)
反射ベクトルと視線ベクトルの内積のn乗により求められ

反射ベクトルは、その場所での法線がわかればいい
「視線ベクトル？」どうやって計算しよ…

3Dとしての
そのピクセルにおける3Dとしての座標から支店を引けばその点における
視線ベクトルが求まります。

つまりこの視線ベクトルと法線ベクトルの内積をとればいい

UV値は、3Dにおいては、TextureCoordinatesという言い方をしたりします。

TextureのCoordinates(座標)なので、テクスチャ座標つまりUVを示しています。

実は3Dはたいていの場合、裏側御w描画しません。
このことを「バックフェーズカリング」といいます。
実は、デフォルトの設定で、「頂点の並びが時計回りのものしか描画しない」と
なっています←バックフェーズカリングという。

①裏面が見えるとみっともないから
②裏面を描画するのは意味がないから

-----------------------------------------------------

たいていの場合、ピクセルシェーダに入ってくる座標には
2種類ある(3種類)
0 :	システムバリュー座標(SV_position)=利用しづらい
	補間のルールがちょっとややこしいため、使いづらい
	→ビュー行列プロジェクション行列の両方をかけられた後なので
		純粋な絶対座標ではない→3D座標を復元できない
1 : システムバリューではない、WVP行列をかけた座標
2 : ワールド座標を保持している座標

ピクセルシェーダ側で3Dの座標を使用したい場合は2を使用する

今回のディゾルヴであれば、この2の座標と高さを比較して、
特定の高さであればdiscard(そのピクセル書き込みをなかったことにする)
している。

輪切り系の処理をする場合、バックフェースカリングはOFFにしておきましょう
バックフェーズカリング:裏面を描画しない
	(カメラから見て時計回りが表という判定になっています)

どうやってOFFにするのか…実は、DxLibのMV1モデルは、複数のメッシュと
フレームからできている。
メッシュ：マテリアルごとに分かれている
フレーム：ボーンにかかわってる概念

切断面のエッジを光らせる
①切断面が1.0で、そこから離れると0になるような計算を行う
	→２つの値が一致している部分を光らせたい
	二つの値をA,Bとおくと
	一致している部分は当然A=Bです。これを移行すると
	A-B=0
	ということはf(A,B)=1,f(A-B±C)=0としたい。
	もっとも単純なのはone-minus(反転)(1.0-t)
	one-minusとは、取りうる値が0～1の時に、その結果を反転するもの
	である。例えば0～t～1の場合
	(1～t)の範囲はt=0の時1で、t=1の時0になる。0.5の時は0.5
②	①だと範囲が広すぎるため、pow関数を用いて明るい部分を絞る
	powとは累乗の事(乗算)(f(t))^n
	CGにおいて累乗は、影響範囲を絞るときに使用されます(範囲が0～1)
	なぜ累乗が使用されるのかというと、範囲を0～1に限定した場合
	1^nはn=∞でも1である
	0^nはn=∞でも0である
	その中間地点についてですが
	累乗すればするほど、1からちょっとでも離れると0に近づく
	→明るい部分とか、影響範囲を絞るときに使用されます
	powのコストはsqrtとあまり変わらないので、使うことに躊躇しなくていい
	
③ディゾルヴ時にノイズを乗っける。今回は雲模様を持ってきました。
	ディゾルヴの変化範囲の10分の1くらいにしておきましょう
	変化範囲とイコールだと、何もしていなくても、消え始めている。
	仮に変化範囲がt=0～1だとして、ディゾルヴテクスチャの範囲をd=0～1だとすると
	t+d=0～2
	(t+d)/2=(0～2)/2
	これだと、tの範囲が1/2になるので、ちょっとまずい
	なので、ディゾルヴテクスチャの影響をちょっと小さくする。
	t+d/10
	(0～1.1)/1.1
	
	
リムライト：モデルの外側を光らせる(後光のような演出ができる)
	視線ベクトルと、法線ベクトルの内積の反転部分に色付ける
	rim = 1.0 - satureta(dot(視線ベクトル,法線ベクトル))
	もちろん、内積だと範囲が広すぎるのでpowで絞る
	rim = 
	
	①内積をとると、当然正面が明るくなります。
	②これだとやりたいことの逆じゃん(端っこを明るくしたい)
	③その結果をpow関数で絞ります

深度バッファとは、特定のピクセルに描くべきモデルの色を決定する前に
それが「一番手前なのか？」ということを判別するために存在するバッファである。

プロジェクション行列は、頂点バッファ内の変換の際に見える範囲を
-1～x～+1
-1～y～+1
 0～z～1
変換するものです。なので、z(深度)の範囲は0～1以外にない
near～Far→0～1
 
ルールはいたって簡単です。
①まず。全体を1.0で初期化する(これによりすべてFarになる)
②モデルの描画を行う際に、そのモデルの深度値(Z値)をバッファに書き込みます
③次のモデルを描画する際に描画の前に深度値をチェックします。
	すでに書き込まれている深度値と、自分の深度値を比較して、自分の方が近いなら
	描画を行ったうえで、深度値を自分の深度値に書き換えます。
	もし、すでに書き込まれている深度値の方が小さいならば、自分より近い物体が
	あるということなので、描画はせず、深度値も書き込まない→捨てられる
	
これを繰り返すことで、常に一番近いピクセルのみが描画されることになる。
→深度バッファ法といいます。

深度バッファを利用しているCG効果
①シャドウマップ
	光源からワールドを撮影します。この時に得られた深度値を保管しておきます。
	今度は視点からワールドを見た時に、視点からの距離を測りながら深度値と
	比較します。
	シャドウマップの深度値よりも大きい部分は、光源に近いモデルに
	隠されているはずなので、そこは影が落ちたとみなして暗くする
②被写界深度
	ピントが合っていない部分をぼかす
	深度値を見て、フォーカスがあっているモデルの深度値に近い部分以外を
	後からぼかす
	①一度レンダリングする
	②深度値を参照する
	③1の結果を2の深度値によってぼかす
	
③輪郭線を表示する
	輪郭線を置くべき場所
		i.法線が急激に変わるところ
		ii.色が急激に変わるところ
		iii.深度値が急激に変わるところ
	深度値が急に変化するということは、手前の物体遠くの物体に距離があるということ
	通常そういった部分に、輪郭を描くからです。
	
④ちょっと変わった使い方をすると、壁の向こうの敵を光らせるようなこともできます。

ただし、DxLibでは残念なことに、深度バッファに直接アクセスできません。

そこで、マルチレンダーターゲットに対して、深度値を書き込んでみます。

深度値を書き込むときの注意点…
深度値は24bitや32bitが使用される。これは32bitで普通のfloatレベル
なのですが、ちょっとめんどくさい部分があります。

何かというとDxLibのレンダーターゲットは、細工しないと必ずRGBAバッファになる
ここに馬鹿正直に書き込むと32bitどころか8bitになる

深度値とは:"超大雑把"にいうと視点からの距離を
			Near～Farの範囲内で正規化したもの
			ここでいう正規化とは、Near=0.0でFar=1.0に
			なるようにしたものである。
			
何ですが、厳密にいうとちょっとだけ違ってて
	プロジェクション行列(透視変換)によって、
	視錐台が直方体に変換された、その直方体の
	Z方向の値(0～1)が深度値です。
	
なんで、Z値と言ったり、深度値と言ったりするの？
大昔はDirectXとOpenGLしかなかったので、Z値=奥行だったので
始点から遠ざかる方向の値はZ値でよかったんですよ。
でも、昨今、MayaとかUnrealEngineとかではZは上方向を表します。

余談ですが、なぜこれらのツールではZが上方向なのか
というと、海外では見下ろし支店のゲームが主流で
この場合、Xが横、Yが置く方向という認識でした。このため
3Dになった時に、上方向は残ったZが割り当てられた

こういった流派の違い、

物理ベース→法線マップ→トゥーン

物理ベースレンダリング
ベースカラー(アルベド):真正面から白色光を当てた時の色(物体本来の色)
ラフネス(スムースネス):表面がザラザラかツルツルか
メタリック:金属感(具体的には、金属管が低いと物質の色が強く出る
					金属感が強いと周囲光が強く出る←すごくおおざっぱ)
PBRでは基本的に環境マップを用いる(用いなくてもレンダリング方程式がPBRならPBRですが)
環境マップがないと、計算式がPBRでもそれっぽく見えません。

そういう意味で基本的には周囲光ありき
この周囲光をあらかじめ撮影しておいた周囲の画像を用いてそれを光源として扱う事を

ImageBasedLighting(IBL)といいます。本当はこれが光源なので、いちいち光源として計算するんですが
この時に、ラフネス値が高い場合は、表面がザラザラしているため、その点を見た時に目に入ってくる
光が一点じゃない(十分つるつるなら、静反射方向の風景が見えますが、ザラザラだと反射する方向も
バラバラなので、ボケて見える)

ラフネス値が低い→IBLの値をそのままサンプリングする
ラフネス値が高い→IBLをぼかした値をサンプリングする

本当は、反射はランダム方向なので、ここで乱数が使われたりします。

本当はレンダリング方程式というのは、勝ちでやばいやつです。

調べたらこんなのが出てきます
L=∫f(i,ω)L(x,ω)(ω・N)dω

これを解こうとしないでください。そもそも解けません(高校数学のようなやり方では)
これは何なのかというと、「こういう計算してね」ということを数式で表現している。

数式は、「日常の言葉と同じ」

∫やΣは「対象をぜーんぶ足してね」
Σはデジタルに足す(離散)
∫はアナログに足す(連続)

「足してね」はわかった。でも、アナログって無限にあるから、足して持ってくることなんてできません。

→じゃあどうする？
代表点をランダムに取得して、それを足し合わせることで「統計的結果(統計的合計)を得る。
ランダム取得で、アナログの結果を得る→「モンテカルロ法」
もちろんサンプリング数を増やせば増やすほど、リアルに近づいていきますが、

L=∫●●dω
ときたら、この中に書いてある式を、統計的に合計する(ランダムサンプリングする)

f(i,ω):フレネル項(特定の計算←関数)→光と法線が直交に近づけば反射率が上がる
L(x,ω):その点における放射輝度
(ω・N)←法線ベクトルと入射光の内積

さすがにそんなことやってられないので、簡易版としては
明るさの計算そのものは、古典的レンダリングで行い、












